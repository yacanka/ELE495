{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-22T03:34:55.777654Z","iopub.status.busy":"2024-03-22T03:34:55.776822Z","iopub.status.idle":"2024-03-22T03:34:59.081236Z","shell.execute_reply":"2024-03-22T03:34:59.080010Z","shell.execute_reply.started":"2024-03-22T03:34:55.777622Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision import models\n","from torchvision.datasets import ImageFolder\n","import torch.nn as nn\n","import numpy as np\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import torchvision.models as models\n","import time\n","from PIL import Image"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:03.551919Z","iopub.status.busy":"2024-03-22T03:35:03.550804Z","iopub.status.idle":"2024-03-22T03:35:03.808946Z","shell.execute_reply":"2024-03-22T03:35:03.808130Z","shell.execute_reply.started":"2024-03-22T03:35:03.551882Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["resnet = models.resnet18(pretrained=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:07.268722Z","iopub.status.busy":"2024-03-22T03:35:07.267831Z","iopub.status.idle":"2024-03-22T03:35:19.798198Z","shell.execute_reply":"2024-03-22T03:35:19.796506Z","shell.execute_reply.started":"2024-03-22T03:35:07.268690Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-20          [-1, 128, 28, 28]             256\n","             ReLU-21          [-1, 128, 28, 28]               0\n","           Conv2d-22          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-23          [-1, 128, 28, 28]             256\n","           Conv2d-24          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-25          [-1, 128, 28, 28]             256\n","             ReLU-26          [-1, 128, 28, 28]               0\n","       BasicBlock-27          [-1, 128, 28, 28]               0\n","           Conv2d-28          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-29          [-1, 128, 28, 28]             256\n","             ReLU-30          [-1, 128, 28, 28]               0\n","           Conv2d-31          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-36          [-1, 256, 14, 14]             512\n","             ReLU-37          [-1, 256, 14, 14]               0\n","           Conv2d-38          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-39          [-1, 256, 14, 14]             512\n","           Conv2d-40          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-41          [-1, 256, 14, 14]             512\n","             ReLU-42          [-1, 256, 14, 14]               0\n","       BasicBlock-43          [-1, 256, 14, 14]               0\n","           Conv2d-44          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-45          [-1, 256, 14, 14]             512\n","             ReLU-46          [-1, 256, 14, 14]               0\n","           Conv2d-47          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-48          [-1, 256, 14, 14]             512\n","             ReLU-49          [-1, 256, 14, 14]               0\n","       BasicBlock-50          [-1, 256, 14, 14]               0\n","           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n","             ReLU-53            [-1, 512, 7, 7]               0\n","           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n","           Conv2d-56            [-1, 512, 7, 7]         131,072\n","      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n","             ReLU-58            [-1, 512, 7, 7]               0\n","       BasicBlock-59            [-1, 512, 7, 7]               0\n","           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n","             ReLU-62            [-1, 512, 7, 7]               0\n","           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n","             ReLU-65            [-1, 512, 7, 7]               0\n","       BasicBlock-66            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                 [-1, 1000]         513,000\n","================================================================\n","Total params: 11,689,512\n","Trainable params: 11,689,512\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 62.79\n","Params size (MB): 44.59\n","Estimated Total Size (MB): 107.96\n","----------------------------------------------------------------\n"]}],"source":["!pip install torchsummary\n","from torchsummary import summary\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","resnet = resnet.to(device)\n","summary(resnet, (3, 224, 224))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:29.107056Z","iopub.status.busy":"2024-03-22T03:35:29.106114Z","iopub.status.idle":"2024-03-22T03:35:29.119795Z","shell.execute_reply":"2024-03-22T03:35:29.118648Z","shell.execute_reply.started":"2024-03-22T03:35:29.107011Z"},"trusted":true},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["resnet"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:33.723365Z","iopub.status.busy":"2024-03-22T03:35:33.722666Z","iopub.status.idle":"2024-03-22T03:35:33.727999Z","shell.execute_reply":"2024-03-22T03:35:33.726867Z","shell.execute_reply.started":"2024-03-22T03:35:33.723336Z"},"trusted":true},"outputs":[],"source":["resnet = torch.nn.Sequential(*list(resnet.children())[:-1])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:36.576163Z","iopub.status.busy":"2024-03-22T03:35:36.575332Z","iopub.status.idle":"2024-03-22T03:35:36.581459Z","shell.execute_reply":"2024-03-22T03:35:36.580536Z","shell.execute_reply.started":"2024-03-22T03:35:36.576134Z"},"trusted":true},"outputs":[],"source":["last_10_params = list(resnet.parameters())[-10:]\n","\n","for param in resnet.parameters():\n","    param.requires_grad = False\n","    \n","for param in last_10_params:\n","    param.requires_grad = True\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:38.882434Z","iopub.status.busy":"2024-03-22T03:35:38.881627Z","iopub.status.idle":"2024-03-22T03:35:38.890576Z","shell.execute_reply":"2024-03-22T03:35:38.889422Z","shell.execute_reply.started":"2024-03-22T03:35:38.882400Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU(inplace=True)\n","  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (5): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (6): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (7): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["resnet"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:50.349794Z","iopub.status.busy":"2024-03-22T03:35:50.349037Z","iopub.status.idle":"2024-03-22T03:35:50.353786Z","shell.execute_reply":"2024-03-22T03:35:50.352771Z","shell.execute_reply.started":"2024-03-22T03:35:50.349763Z"},"trusted":true},"outputs":[],"source":["train_dir = \"/kaggle/input/dataset/train\"\n","val_dir = \"/kaggle/input/dataset/val\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:53.053983Z","iopub.status.busy":"2024-03-22T03:35:53.053086Z","iopub.status.idle":"2024-03-22T03:35:53.060587Z","shell.execute_reply":"2024-03-22T03:35:53.059613Z","shell.execute_reply.started":"2024-03-22T03:35:53.053932Z"},"trusted":true},"outputs":[],"source":["train_transform =  transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.RandomRotation(degrees = 15),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","\n","val_transform = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:55.887781Z","iopub.status.busy":"2024-03-22T03:35:55.886922Z","iopub.status.idle":"2024-03-22T03:35:55.909935Z","shell.execute_reply":"2024-03-22T03:35:55.909217Z","shell.execute_reply.started":"2024-03-22T03:35:55.887751Z"},"trusted":true},"outputs":[],"source":["train_dataset = ImageFolder(root=train_dir, transform=train_transform)\n","val_dataset = ImageFolder(root=val_dir, transform=val_transform)\n","\n","train_loader = DataLoader(dataset = train_dataset, batch_size=1, shuffle=True)\n","val_loader = DataLoader(dataset = val_dataset, batch_size=1)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:35:57.979683Z","iopub.status.busy":"2024-03-22T03:35:57.979336Z","iopub.status.idle":"2024-03-22T03:35:57.990494Z","shell.execute_reply":"2024-03-22T03:35:57.989721Z","shell.execute_reply.started":"2024-03-22T03:35:57.979659Z"},"trusted":true},"outputs":[],"source":["class CustomResnet(nn.Module):\n","    def __init__(self):\n","        super(CustomResnet, self).__init__()\n","        self.resnet = resnet\n","        self.flatten = nn.Flatten()\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 64)\n","        self.fc5 = nn.Linear(64, 32)\n","        self.fc6 = nn.Linear(32,5)\n","\n","    def forward(self, x):\n","        x = self.resnet(x)        \n","        x = self.flatten(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        x = self.fc4(x)\n","        x = self.fc5(x)\n","        x = self.fc6(x)\n","        return x\n","\n","model = CustomResnet()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:36:02.242064Z","iopub.status.busy":"2024-03-22T03:36:02.241685Z","iopub.status.idle":"2024-03-22T03:36:02.252883Z","shell.execute_reply":"2024-03-22T03:36:02.252015Z","shell.execute_reply.started":"2024-03-22T03:36:02.242033Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CustomResnet(\n","  (resnet): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=128, bias=True)\n","  (fc4): Linear(in_features=128, out_features=64, bias=True)\n","  (fc5): Linear(in_features=64, out_features=32, bias=True)\n","  (fc6): Linear(in_features=32, out_features=5, bias=True)\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:36:06.352166Z","iopub.status.busy":"2024-03-22T03:36:06.351798Z","iopub.status.idle":"2024-03-22T03:36:06.358307Z","shell.execute_reply":"2024-03-22T03:36:06.357321Z","shell.execute_reply.started":"2024-03-22T03:36:06.352139Z"},"trusted":true},"outputs":[],"source":["from  torch import optim\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:36:09.987356Z","iopub.status.busy":"2024-03-22T03:36:09.986525Z","iopub.status.idle":"2024-03-22T03:36:09.991513Z","shell.execute_reply":"2024-03-22T03:36:09.990503Z","shell.execute_reply.started":"2024-03-22T03:36:09.987325Z"},"trusted":true},"outputs":[],"source":["def saveModel(): \n","    path = \"./NetModel.pth\" \n","    torch.save(model.state_dict(), path) "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:36:12.238546Z","iopub.status.busy":"2024-03-22T03:36:12.237839Z","iopub.status.idle":"2024-03-22T03:36:12.249810Z","shell.execute_reply":"2024-03-22T03:36:12.248796Z","shell.execute_reply.started":"2024-03-22T03:36:12.238513Z"},"trusted":true},"outputs":[],"source":["def train(num_epochs): \n","    best_accuracy = 0.0 \n","     \n","    print(\"Begin training...\") \n","    for epoch in range(1, num_epochs+1): \n","        running_train_loss = 0.0 \n","        running_accuracy = 0.0 \n","        running_vall_loss = 0.0 \n","        total = 0 \n"," \n","        # Training Loop \n","        for data in train_loader: \n","            inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs] \n","            inputs = inputs.to(device)\n","            outputs = outputs.to(device)\n","            \n","            optimizer.zero_grad()   # zero the parameter gradients          \n","            predicted_outputs = model(inputs)   # predict output from the model \n","            train_loss = loss_fn(predicted_outputs, outputs)   # calculate loss for the predicted output  \n","            train_loss.backward()   # backpropagate the loss \n","            optimizer.step()        # adjust parameters based on the calculated gradients \n","            running_train_loss +=train_loss.item()  # track the loss value \n"," \n","        # Calculate training loss value \n","        train_loss_value = running_train_loss/len(train_loader) \n"," \n","        # Validation Loop \n","        with torch.no_grad(): \n","            model.eval() \n","            for data in val_loader: \n","                inputs, outputs = data\n","                inputs = inputs.to(device)\n","                outputs = outputs.to(device)\n","                predicted_outputs = model(inputs) \n","                val_loss = loss_fn(predicted_outputs, outputs) \n","             \n","               # The label with the highest value will be our prediction \n","                _, predicted = torch.max(predicted_outputs, 1) \n","                running_vall_loss += val_loss.item()  \n","                total += outputs.size(0) \n","                running_accuracy += (predicted == outputs).sum().item() \n"," \n","        # Calculate validation loss value \n","        val_loss_value = running_vall_loss/len(val_loader) \n","                \n","        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n","        accuracy = (100 * running_accuracy / total)     \n"," \n","        # Save the model if the accuracy is the best \n","        if accuracy > best_accuracy: \n","            saveModel() \n","            best_accuracy = accuracy \n","         \n","        # Print the statistics of the epoch \n","        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:36:15.068934Z","iopub.status.busy":"2024-03-22T03:36:15.067979Z","iopub.status.idle":"2024-03-22T03:41:21.019910Z","shell.execute_reply":"2024-03-22T03:41:21.018810Z","shell.execute_reply.started":"2024-03-22T03:36:15.068902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Begin training...\n","Completed training batch 1 Training Loss is: 1.6398 Validation Loss is: 1.6194 Accuracy is 13 %\n","Completed training batch 2 Training Loss is: 1.3411 Validation Loss is: 1.3292 Accuracy is 41 %\n","Completed training batch 3 Training Loss is: 0.9454 Validation Loss is: 0.9025 Accuracy is 55 %\n","Completed training batch 4 Training Loss is: 0.8949 Validation Loss is: 1.6264 Accuracy is 27 %\n","Completed training batch 5 Training Loss is: 0.6577 Validation Loss is: 0.4295 Accuracy is 82 %\n","Completed training batch 6 Training Loss is: 0.7085 Validation Loss is: 0.4219 Accuracy is 81 %\n","Completed training batch 7 Training Loss is: 0.4834 Validation Loss is: 0.8946 Accuracy is 74 %\n","Completed training batch 8 Training Loss is: 0.4983 Validation Loss is: 0.3315 Accuracy is 85 %\n","Completed training batch 9 Training Loss is: 0.5954 Validation Loss is: 0.3940 Accuracy is 83 %\n","Completed training batch 10 Training Loss is: 0.3727 Validation Loss is: 0.3593 Accuracy is 82 %\n"]}],"source":["num_epochs = 10\n","train(num_epochs)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:43:02.619664Z","iopub.status.busy":"2024-03-22T03:43:02.619268Z","iopub.status.idle":"2024-03-22T03:43:02.632528Z","shell.execute_reply":"2024-03-22T03:43:02.631516Z","shell.execute_reply.started":"2024-03-22T03:43:02.619634Z"},"trusted":true},"outputs":[],"source":["image = \"/kaggle/input/test-data/multiple/ayva4.jpg\"\n","image = Image.open(image)\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","image = transform(image)\n","image = image.unsqueeze(0)  # Batch boyutunu ekleyin\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","image = image.to(device)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T03:43:09.484491Z","iopub.status.busy":"2024-03-22T03:43:09.484118Z","iopub.status.idle":"2024-03-22T03:43:09.496343Z","shell.execute_reply":"2024-03-22T03:43:09.495358Z","shell.execute_reply.started":"2024-03-22T03:43:09.484461Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Class: ayva\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    outputs = model(image)\n","_, predicted = torch.max(outputs, 1)\n","predicted_class = predicted.item()\n","class_names = ['ayva', 'elma', 'muz', 'nar', 'portakal']\n","predicted_label = class_names[predicted_class]\n","print(\"Predicted Class:\", predicted_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#trained_resnet = CustomResnet()\n","#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#saved_model_path = \"/kaggle/input/model100/pytorch/model100video/1/model_video_data.pth\"\n","#trained_resnet.load_state_dict(torch.load(saved_model_path, map_location=device))\n","\n","# Modelü değerlendirme moduna al\n","#trained_resnet.eval()"]},{"cell_type":"markdown","metadata":{},"source":["https://www.kaggle.com/code/mertbykkdan/customdata-imageclassification"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4474819,"sourceId":7671822,"sourceType":"datasetVersion"},{"datasetId":4474876,"sourceId":7671914,"sourceType":"datasetVersion"},{"datasetId":4486618,"sourceId":7688284,"sourceType":"datasetVersion"},{"datasetId":4489057,"sourceId":7691926,"sourceType":"datasetVersion"},{"modelInstanceId":9549,"sourceId":11807,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
